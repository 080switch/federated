{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AftvNA5VMemJ"
      },
      "source": [
        "# Federated Learning for Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zs2LgZBOMt4M"
      },
      "source": [
        "In this tutorial, we use the classic MNIST training example to introduce the\n",
        "Federated Learning (FL) component of TFF - a set of higher-level interfaces that\n",
        "can be used to perform common types of federated learning tasks, such as\n",
        "federated training, against user-supplied models implemented in TensorFlow.\n",
        "\n",
        "This tutorial, and the Federated Learning API, are intended primarly for users\n",
        "who will want to plug their own TensorFlow models into TFF, treating the latter\n",
        "mostly as a black box. For a more in-depth understanding of TFF and how to\n",
        "implement your own federated learning algorithms, consider also reviewing as a\n",
        "follow-up the tutorial on lower-level interfaces -\n",
        "[Custom Federated Algorithms with the Federated Core API](custom_federated_algorithms.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Before we start\n",
        "\n",
        "Before we start, please run the following to make sure that your environment is\n",
        "correctly setup. If you don't see a greeting, please refer to the\n",
        "[Installation](../install.md) guide for instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 12134,
          "status": "ok",
          "timestamp": 1550097625256,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "8BKyHkMxKHfV",
        "outputId": "78fe32e5-0b5a-4470-b532-55411586bfd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow_federated import python as tff\n",
        "\n",
        "nest = tf.contrib.framework.nest\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.enable_resource_variables()\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Cyy2AWbLMKj"
      },
      "source": [
        "## Preparing the input data\n",
        "\n",
        "Let's start with the data. Federated Learning requires a federated data set,\n",
        "i.e., a collection of data from multipe users. Federated data is typically\n",
        "non-[i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables),\n",
        "which poses a unique set of challenges. To illustrate this, we're going to\n",
        "manuallly craft a scenario with 10 users, each of whom contributes data on how\n",
        "to recognize a different digit, and we'll use the federated learning framework\n",
        "to learn a combined model.\n",
        "\n",
        "Let's start by loading the standard MNIST data from `tf.keras.datasets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NayDhCX6SjwE"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "mnist_train, _ = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tA5YXr9ayfMQ"
      },
      "source": [
        "The standard MNIST data comes as a pair of Numpy arrays, the first with 28x28\n",
        "pixel images, and the second with the integers that correspond to the digits,\n",
        "both with the leading batching dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 17,
          "status": "ok",
          "timestamp": 1550097626089,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "bW0ZMmdaSr1w",
        "outputId": "f08f38a6-a42c-4159-910b-c07600608c9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(x.dtype, x.shape) for x in mnist_train]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lMd01egqy9we"
      },
      "source": [
        "Here's a helper method that will construct a portion training data for a given\n",
        "digit, in batches of a given size, with images flattened into vectors and\n",
        "normalized to simplify the model code, and with the features renamed to `x` and\n",
        "`y` as expected by Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cyG_BMraSuu_"
      },
      "outputs": [],
      "source": [
        "NUM_EXAMPLES_PER_DIGIT = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def get_training_data_for_digit(digit):\n",
        "  images, digits = mnist_train\n",
        "  output_sequence = []\n",
        "  all_samples = [i for i, d in enumerate(digits) if d == digit]\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_DIGIT), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i + BATCH_SIZE]\n",
        "    output_sequence.append(collections.OrderedDict([\n",
        "        ('x', np.array([images[i].flatten() / 255.0 for i in batch_samples],\n",
        "                       dtype=np.float32)),\n",
        "        ('y', np.array([digits[i] for i in batch_samples], dtype=np.int32))\n",
        "    ]))\n",
        "  return output_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERm-GZUy0D59"
      },
      "source": [
        "One of the ways one can use to feed federated data to TFF is as a simple Python\n",
        "list of per-user data sets. We can construct such a representation for our 10\n",
        "users as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mat6bPUYzVYl"
      },
      "outputs": [],
      "source": [
        "federated_train_data = [get_training_data_for_digit(d) for d in xrange(10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "658qI9TL0U_E"
      },
      "source": [
        "As a quick sanity check, let's grab the first batch of data from the first user\n",
        "(we're going to meed a sample data batch for use with Keras, anyway), and check\n",
        "the dimensions to make sure the data looks as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2lr0WP8C9eGF"
      },
      "outputs": [],
      "source": [
        "sample_batch = federated_train_data[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 16,
          "status": "ok",
          "timestamp": 1550097627897,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "zkVl5DWW9g87",
        "outputId": "136099f2-5463-4712-f4d6-2fc38ec0ef56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('x', (dtype('float32'), (100, 784))), ('y', (dtype('int32'), (100,)))])"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nest.map_structure(lambda x: (x.dtype, x.shape), sample_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HOxq4tbi9m8-"
      },
      "source": [
        "## Creating a model with Keras\n",
        "\n",
        "If you are using Keras, you likely already have code that constructs a Keras\n",
        "model. Here's an example based on the simple Keras model posted on\n",
        "[the tensorflow.org tutorials page](https://www.tensorflow.org/tutorials); the\n",
        "only modification we make is removing the dropout layer. This is not needed,\n",
        "since we will be combining models across users; in this case, the process of\n",
        "federated averaging in and by itself will help to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LYCsJGJFWbqt"
      },
      "outputs": [],
      "source": [
        "def create_compiled_keras_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      optimizer = tf.keras.optimizers.SGD(0.1),\n",
        "      metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NHdraKFH4OU2"
      },
      "source": [
        "In order to use any model with TFF, it needs to be wrapped in an instance of the\n",
        "`tff.learning.Model` interface, which exposes methods to stamp the model's\n",
        "forward pass, metadata properties, etc., similarly to Keras, but also introduces\n",
        "additional elements, such as ways to control the process of computing federated\n",
        "metrics. Let's not worry about this for now; if you have a compiled Keras model\n",
        "like the one we've just defined above, you can have TFF wrap it for you by\n",
        "invoking `tff.learning.from_compiled_keras_model`, passing the model and a\n",
        "sample data batch as arguments, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Q3ynrxd53HzY"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  keras_model = create_compiled_keras_model()\n",
        "  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XJ5E3O18_JZ6"
      },
      "source": [
        "## Training the model on federated data\n",
        "\n",
        "Now that we have a model wrapped as `tff.learning.Model` for use with TFF, we\n",
        "can let TFF construct a federated averaging algorithm by invoking the helper\n",
        "function `tff.learning.build_federated_averaging_process`, as follows.\n",
        "\n",
        "Keep in mind that the argument needs to be a constructor (such as `model_fn`\n",
        "above), not the already-constructed instance, so that the construction of your\n",
        "model can happen in a context controlled by TFF (if you're curious about the\n",
        "reasons for this, we encourage you to read the follow-up tutorial on\n",
        "[custom algorithms](custom_federated_algorithms.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sk6mjOfycX5N"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.build_federated_averaging_process(model_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f8FpvN2n67sm"
      },
      "source": [
        "What did just happen? TFF has constructed a pair of *federated computations* and\n",
        "packaged them into a standardized iterator-like structure\n",
        "`tff.utils.IterativeProcess` in which these computations are available as a pair\n",
        "of properties `initialize` and `next`.\n",
        "\n",
        "In a nutshell, *federated computations* are programs in TFF's internal language\n",
        "that can express various federated algorithms (you can find more about this in\n",
        "the [custom algorithms](custom_federated_algorithms.ipynb) tutorial). In this\n",
        "case, the two computations generated and packed into `iterative_process`\n",
        "implement [federated model averaging](https://arxiv.org/abs/1602.05629).\n",
        "\n",
        "In one of the upcoming releases of the framework, we'll enable you to deploy\n",
        "such computations for execution in real environments, such as on groups of\n",
        "`Android` devices. In this tutorial, we'll execute federated computations in a\n",
        "simple interpreted environment in a simulator, inside this notebook. To execute\n",
        "a computation in a simulator, you simply invoke them like Python functions, as\n",
        "we will demonstrate shortly. This default interpreted environment is not\n",
        "designed for high performance, but it will suffice for this tutorial.\n",
        "\n",
        "Let's start with the `initialize` computation. As is the case for all federated\n",
        "computations, you can think of it as a function. The computation takes no\n",
        "arguments, and returns one result - the representation of the state of the\n",
        "federated averaging process on the server. While we don't want to dive into the\n",
        "details of TFF, it may be instructive to see what this state looks like. You can\n",
        "visualize it as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 237,
          "status": "ok",
          "timestamp": 1550098006947,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Z4pcfWsUBp_5",
        "outputId": "fb2ecfb0-cc40-44ee-8342-f63ce8a6eb0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'( -\u003e \u003cmodel=\u003ctrainable=\u003cdense/bias=float32[512],dense/kernel=float32[784,512],dense_1/bias=float32[10],dense_1/kernel=float32[512,10]\u003e,non_trainable=\u003c\u003e\u003e,optimizer_state=\u003cint64\u003e\u003e@SERVER)'"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(iterative_process.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v1gbHQ_7BiyT"
      },
      "source": [
        "While the above type signature may at first seem a bit cryptic, you can\n",
        "recognize that the server state consists of a`model`(the initial model\n",
        "parameters for MNIST that will be distributed to all devices), and\n",
        "`optimizer_state` (additional information maintained by the server, such as the\n",
        "number of rounds to use for hypermarameter schedules, etc.).\n",
        "\n",
        "Let's invoke the `initialize` computation to construct the server state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6cagCWlZmcch"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TjjxTx9e_rMd"
      },
      "source": [
        "The second of the pair of federated computations, `next`, represents a single\n",
        "round of federated averaging, which consists of pushing the server state\n",
        "(including the model parameters) to the clients, on-device training on their\n",
        "local data, collecting and averaging model updates, and producing a new updated\n",
        "model at the server.\n",
        "\n",
        "Conceptually, you can think of `next` as having a functional type signature\n",
        "`SERVER_STATE, FEDERATED_DATA -\u003e SERVER_STATE, TRAINING_METRICS`.\n",
        "\n",
        "Let's run a single round of training and visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F3M_W9dDE6Tm"
      },
      "outputs": [],
      "source": [
        "#@test {\"timeout\": 300}\n",
        "state, metrics = iterative_process.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 30,
          "status": "ok",
          "timestamp": 1550099113361,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ggFtLPvZGtSV",
        "outputId": "ab095cc3-b82d-451e-c0ef-bc88acb8678c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003csparse_categorical_accuracy=0.9069,loss=0.285775\u003e'"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "str(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UmhReXt9G4A5"
      },
      "source": [
        "Let's run a few more rounds, just to confirm that the loss decreases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 104
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 460700,
          "status": "ok",
          "timestamp": 1550099634788,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "qrJkQuCRJP9C",
        "outputId": "8621929c-5609-43a3-d4dc-45081971d306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u003csparse_categorical_accuracy=0.9162,loss=0.256639\u003e\n",
            "\u003csparse_categorical_accuracy=0.9331,loss=0.23417\u003e\n",
            "\u003csparse_categorical_accuracy=0.9478,loss=0.215587\u003e\n",
            "\u003csparse_categorical_accuracy=0.9584,loss=0.199654\u003e\n",
            "\u003csparse_categorical_accuracy=0.9652,loss=0.185741\u003e\n"
          ]
        }
      ],
      "source": [
        "#@test {\"skip\": true}\n",
        "for _ in xrange(5):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print (metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T4hneAcb-F2l"
      },
      "source": [
        "## Customizing the model implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uqRD72WQC4u1"
      },
      "outputs": [],
      "source": [
        "MnistVariables = collections.namedtuple(\n",
        "    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H3GQHLNqCfMU"
      },
      "outputs": [],
      "source": [
        "def create_mnist_variables():\n",
        "  return MnistVariables(\n",
        "      weights = tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(784, 10)),\n",
        "          name='weights',\n",
        "          trainable=True),\n",
        "      bias = tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n",
        "          name='bias',\n",
        "          trainable=True),\n",
        "      num_examples = tf.Variable(0.0, name='num_examples', trainable=False),\n",
        "      loss_sum = tf.Variable(0.0, name='loss_sum', trainable=False),\n",
        "      accuracy_sum = tf.Variable(0.0, name='accuracy_sum', trainable=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZYSRAl-KCvC7"
      },
      "outputs": [],
      "source": [
        "def mnist_forward_pass(variables, batch):\n",
        "  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)\n",
        "  predictions = tf.cast(tf.argmax(y, 1), tf.int32)\n",
        "\n",
        "  loss = -tf.reduce_mean(tf.reduce_sum(\n",
        "      tf.one_hot(batch['y'], 10) * tf.log(y), reduction_indices=[1]))\n",
        "  accuracy = tf.reduce_mean(\n",
        "      tf.cast(tf.equal(predictions, batch['y']), tf.float32))\n",
        "\n",
        "  num_examples = tf.to_float(tf.size(batch['y']))\n",
        "\n",
        "  tf.assign_add(variables.num_examples, num_examples)\n",
        "  tf.assign_add(variables.loss_sum, loss * num_examples)\n",
        "  tf.assign_add(variables.accuracy_sum, accuracy * num_examples)\n",
        "\n",
        "  return loss, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RkAZXhjGEekp"
      },
      "outputs": [],
      "source": [
        "def get_local_mnist_metrics(variables):\n",
        "  return collections.OrderedDict([\n",
        "      ('num_examples', variables.num_examples),\n",
        "      ('loss', variables.loss_sum / variables.num_examples),\n",
        "      ('accuracy', variables.accuracy_sum / variables.num_examples)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BMr2PwkfExFI"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation\n",
        "def aggregate_local_mnist_metrics(metrics):\n",
        "  return {\n",
        "      'num_examples': tff.federated_sum(metrics.num_examples),\n",
        "      'loss': tff.federated_average(metrics.loss, metrics.num_examples),\n",
        "      'accuracy': tff.federated_average(metrics.accuracy, metrics.num_examples)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "blQGiTQFS9_r"
      },
      "outputs": [],
      "source": [
        "class MnistModel(tff.learning.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    self._variables = create_mnist_variables()\n",
        "\n",
        "  @property\n",
        "  def trainable_variables(self):\n",
        "    return [self._variables.weights, self._variables.bias]\n",
        "\n",
        "  @property\n",
        "  def non_trainable_variables(self):\n",
        "    return []\n",
        "\n",
        "  @property\n",
        "  def local_variables(self):\n",
        "    return [self._variables.num_examples,\n",
        "            self._variables.loss_sum,\n",
        "            self._variables.accuracy_sum]\n",
        "\n",
        "  @property\n",
        "  def input_spec(self):\n",
        "    return collections.OrderedDict([\n",
        "        ('x', tf.TensorSpec([None, 784], tf.float32)),\n",
        "        ('y', tf.TensorSpec([None], tf.int32))])\n",
        "\n",
        "  @tf.contrib.eager.function(autograph=False)\n",
        "  def forward_pass(self, batch, training=True):\n",
        "    del training\n",
        "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
        "    return tff.learning.BatchOutput(loss=loss, predictions=predictions)\n",
        "\n",
        "  @tf.contrib.eager.function(autograph=False)\n",
        "  def report_local_outputs(self):\n",
        "    return get_local_mnist_metrics(self._variables)\n",
        "\n",
        "  @property\n",
        "  def federated_output_computation(self):\n",
        "    return aggregate_local_mnist_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "q1w7US3PFN2p"
      },
      "outputs": [],
      "source": [
        "class MnistTrainableModel(MnistModel, tff.learning.TrainableModel):\n",
        "\n",
        "  @tf.contrib.eager.defun(autograph=False)\n",
        "  def train_on_batch(self, batch):\n",
        "    output = self.forward_pass(batch)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
        "    optimizer.minimize(output.loss, var_list=self.trainable_variables)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FK3c8_leS9_t"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    MnistTrainableModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Jv_LiggwS9_u"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W0TKgDqHKQaP"
      },
      "outputs": [],
      "source": [
        "#@test {\"timeout\": 300}\n",
        "state, metrics = iterative_process.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 252,
          "status": "ok",
          "timestamp": 1550100097537,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "hmlLydWYKZPc",
        "outputId": "1aeb3ada-e2df-4889-f757-47ae6c06da60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003caccuracy=0.91,loss=0.293638,num_examples=10000.0\u003e'"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "str(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 104
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 333680,
          "status": "ok",
          "timestamp": 1550100436866,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "gFkv0yJEGhue",
        "outputId": "e1da46a9-05f0-4d78-8c42-3038939f4e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u003caccuracy=0.976,loss=0.277596,num_examples=10000.0\u003e\n",
            "\u003caccuracy=0.9786,loss=0.263369,num_examples=10000.0\u003e\n",
            "\u003caccuracy=0.9796,loss=0.25075,num_examples=10000.0\u003e\n",
            "\u003caccuracy=0.98,loss=0.239585,num_examples=10000.0\u003e\n",
            "\u003caccuracy=0.9799,loss=0.229727,num_examples=10000.0\u003e\n"
          ]
        }
      ],
      "source": [
        "#@test {\"skip\": true}\n",
        "for _ in xrange(5):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print (metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Federated Learning for Image Classification",
      "provenance": [
        {
          "file_id": "1ReQJfPpiNTRrFhK-zK6InyBId1n_DGLm",
          "timestamp": 1547751366697
        }
      ],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "32xflLc4NTx-"
      },
      "source": [
        "# Custom Federated Algorithms, Part 2: Implementing Federated Averaging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_igJ2sfaNWS8"
      },
      "source": [
        "This tutorial is the second part of a two-part series that demonstrates how to\n",
        "implement custom types of federated algorithms in TFF using the\n",
        "[Federated Core (FC)](../federated_core.md), which serves as a foundation for\n",
        "the [Federated Learning (FL)](../federated_learning.md) layer.\n",
        "\n",
        "We encourage you to first read the\n",
        "[first part of this series](custom_federated_algorithms_1.ipynb), which\n",
        "introduce some of the key concepts and programming abstractions used here.\n",
        "\n",
        "This second part of the series uses the mechanisms introduced in the first part\n",
        "to implement a simple version of federated training and evaluation algorithms.\n",
        "\n",
        "We encourage you to review the\n",
        "[image classification](federated_learning_for_image_classification.ipynb) and\n",
        "[text generation](federated_learning_for_text_generation.ipynb) tutorials for a\n",
        "higher-level and more gentle introduction to TFF's Federated Learning APIs, as\n",
        "they will help you put the concepts we describe here in context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cuJuLEh2TfZG"
      },
      "source": [
        "## Before we start\n",
        "\n",
        "Before we start, try to run the following \"Hello World\" example to make sure\n",
        "your environment is correctly setup. If it doesn't work, please refer to the\n",
        "[Installation](../install.md) guide for instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 10235,
          "status": "ok",
          "timestamp": 1550717114054,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "-skNC6aovM46",
        "outputId": "6f2ab5d3-fa56-4169-966d-f1bbac1e82c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# NOTE: If you are running a Jupyter notebook and installing a locally built\n",
        "# pip package, you may need to uncomment and run the following after editing\n",
        "# the path to point to the '.whl' file on your local filesystem.\n",
        "#\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install tensorflow_federated-*.whl --user\n",
        "\n",
        "import numpy as np\n",
        "from six.moves import range\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow_federated import python as tff\n",
        "\n",
        "tf.enable_resource_variables()\n",
        "\n",
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "\n",
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iu5Gd8D6W33s"
      },
      "source": [
        "## Implementing federated averaging\n",
        "\n",
        "Now, let's use what we've learned so far to implement a simple version of\n",
        "federated averaging. For symmetry with\n",
        "[Federated Learning for Image Classification](federated_learning_for_image_classification.md),\n",
        "we are going to use the MNIST example, but since this is intended as a low-level\n",
        "tutorial, we are going to bypass the Keras API and `tff.simulation`, write raw\n",
        "model code, and construct a federated data set from scratch.\n",
        "\n",
        "### Preparing federated data sets\n",
        "\n",
        "For the sake of a demonstration, we're going to simulate a scenario in which we\n",
        "have data from 10 users, and each of the users contributes knowledge how to\n",
        "recognize a different digit. This is about\n",
        "non-[i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n",
        "as it gets, and as such, it illustrates well the kind of challenges you may run\n",
        "into working with federated data.\n",
        "\n",
        "First, let's load the standard MNIST data from the TensorFlow website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uThZM4Ds-KDQ"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 80,
          "status": "ok",
          "timestamp": 1550717114847,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "PkJc5rHA2no_",
        "outputId": "8b5d1c88-2e9e-49f6-bdfa-b5b89f60db54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(x.dtype, x.shape) for x in mnist_train]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mFET4BKJFbkP"
      },
      "source": [
        "The data comes as Numpy arrays, one with images and another with digits, both\n",
        "with the first dimension going over the individual examples. Let's write a\n",
        "helper function that formats it in a way compatible with how we feed federated\n",
        "sequences into TFF computations, i.e., as a list of lists - the outer list\n",
        "ranging over the users (digits), the inner ones ranging over batches of data in\n",
        "each client's sequence. As is customary, we will structure each batch as a pair\n",
        "of tensors named `X` and `Y`, each with the leading batch dimension. While at\n",
        "it, we'll also flatten each image into a 784-element vector and rescale the\n",
        "pixels in it into the `0..1` range, so that we don't have to clutter the model\n",
        "logic with data conversions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XTaTLiq5GNqy"
      },
      "outputs": [],
      "source": [
        "NUM_EXAMPLES_PER_USER = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def get_data_for_digit(source, digit):\n",
        "  output_sequence = []\n",
        "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i + BATCH_SIZE]\n",
        "    output_sequence.append({\n",
        "        'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
        "                      dtype=np.float32),\n",
        "        'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})\n",
        "  return output_sequence\n",
        "\n",
        "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
        "\n",
        "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xpNdBimWaMHD"
      },
      "source": [
        "As a quick sanity check, let's look at the `Y` tensor in the last batch of data\n",
        "contributed by the fifth client (the one corresponding to the digit `5`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 101
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 102,
          "status": "ok",
          "timestamp": 1550717117087,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "bTNuL1W4bcuc",
        "outputId": "843848c2-8a36-4a2f-95af-c2d46d423e96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_train_data[5][-1]['y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xgvcwv7Obhat"
      },
      "source": [
        "Just to be sure, let's also look at the image corresponding to the last element of that batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 275
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 307,
          "status": "ok",
          "timestamp": 1550717117531,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "cI4aat1za525",
        "outputId": "646ab185-abea-4a32-993c-9128c1a3366f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAECCAYAAAD3k8IpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "\u003cmatplotlib.figure.Figure at 0xad8ad10\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28, 28), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RSd6UatXbzw-"
      },
      "source": [
        "### Defining a loss function\n",
        "\n",
        "Now that we have the data, let's define a loss function that we can use for\n",
        "training. First, let's define the type of input as a TFF named tuple. Since the\n",
        "size of data batches may vary, we set the batch dimension to `None` to indicate\n",
        "that the size of this dimension is unknown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 81,
          "status": "ok",
          "timestamp": 1550717117701,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "653xv5NXd4fy",
        "outputId": "111d718b-2975-47e1-9c30-f10871385e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003cx=float32[?,784],y=int32[?]\u003e'"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_TYPE = tff.NamedTupleType([\n",
        "    ('x', tff.TensorType(tf.float32, [None, 784])),\n",
        "    ('y', tff.TensorType(tf.int32, [None]))])\n",
        "\n",
        "str(BATCH_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pb6qPUvyh5A1"
      },
      "source": [
        "You may be wondering why we can't just define an ordinary Python type. Recall\n",
        "the discussion in one of the preceding sections, where we explained that while\n",
        "we can express the logic of TFF computations using Python, under the hood TFF\n",
        "computations *are not* Python. The symbol `BATCH_TYPE` defined above represents\n",
        "an abstract TFF type specification. It is important to distinguish this\n",
        "*abstract* TFF type from concrete Python *representation* types, e.g.,\n",
        "containers such as `dict` or `collections.namedtuple` that may be used to\n",
        "represent the TFF type in the body of a Python function. Unlike Python, TFF has\n",
        "a single abstract type constructor `tff.NamedTupleType` for tuple-like\n",
        "containers, with elements that can be individually named or left unnamed. This\n",
        "type is also used to model formal parameters of computations, as TFF\n",
        "computations can formally only declare one parameter and one result - you will\n",
        "see examples of this shortly.\n",
        "\n",
        "Let's now define the TFF type of model parameters, again as a TFF named tuple of\n",
        "*weights* and *bias*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 82,
          "status": "ok",
          "timestamp": 1550717117905,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Og7VViafh-30",
        "outputId": "0abf59d5-4f0b-4fea-db39-fcc3c2091a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003cweights=float32[784,10],bias=float32[10]\u003e'"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_TYPE = tff.NamedTupleType([\n",
        "    ('weights', tff.TensorType(tf.float32, [784, 10])),\n",
        "    ('bias', tff.TensorType(tf.float32, [10]))])\n",
        "\n",
        "str(MODEL_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iHhdaWSpfQxo"
      },
      "source": [
        "With those definitions in place, now we can define the loss for a given model, over\n",
        "a single batch. Note how in the body of `batch_loss`, we access named tuple\n",
        "elements using the dot (`X.Y`) notation, as is standard for TFF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4EObiz_Ke0uK"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)\n",
        "  return -tf.reduce_mean(tf.reduce_sum(\n",
        "      tf.one_hot(batch.y, 10) * tf.log(predicted_y), reduction_indices=[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_DVytYGmnfp5"
      },
      "source": [
        "As expected, computation `batch_loss` returns `float32` loss given the model and\n",
        "a single data batch. Note how the `MODEL_TYPE` and `BATCH_TYPE` have been lumped\n",
        "together into a 2-tuple of formal parameters; you can recognize the type of\n",
        "`batch_loss` as `(\u003cMODEL_TYPE,BATCH_TYPE\u003e -\u003e float32)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 104,
          "status": "ok",
          "timestamp": 1550717118226,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ZGU8HboKndAW",
        "outputId": "859b7412-6db6-42bc-e91f-3c90fde98173"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,\u003cx=float32[?,784],y=int32[?]\u003e\u003e -\u003e float32)'"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(batch_loss.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAnt_UcdnvGa"
      },
      "source": [
        "As a sanity check, let's construct an initial model filled with zeros and\n",
        "compute the loss over the batch of data we visualized above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 266,
          "status": "ok",
          "timestamp": 1550717118575,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "U8Ne8igan3os",
        "outputId": "33235bf1-e442-45c0-d143-995bacb17fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.3025854"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_model = {\n",
        "    'weights': np.zeros([784, 10], dtype=np.float32),\n",
        "    'bias': np.zeros([10], dtype=np.float32)\n",
        "}\n",
        "\n",
        "sample_batch = federated_train_data[5][-1]\n",
        "\n",
        "batch_loss(initial_model, sample_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ckigEAyDAWFV"
      },
      "source": [
        "Note that we feed the TFF computation with the initial model defined as a\n",
        "`dict`, even though the body of the Python function that defines it consumes\n",
        "model parameters as `model.weight` and `model.bias`. Since, as explained\n",
        "earlier, the logic of a TFF computation is defined in a glue language over\n",
        "abstract TFF types, the choice of a physical Python container in this case\n",
        "doesn't matter. The arguments of the call to `batch_loss` aren't simply passed\n",
        "to the body of that function. Indeed, if you remember the earlier discussion in\n",
        "the section on federated computations, the body of `batch_loss` has already been\n",
        "traced earlier - that is, *before* the invocation, not after. TFF acts as the\n",
        "caller to `batch_loss` at the computation definition time, and as the target of\n",
        "invocation at the time `batch_loss` is invoked. In both roles, TFF serves as the\n",
        "bridge between TFF's abstract type system and Python representation types. At\n",
        "the invocation time, TFF will accept most standard Python container types\n",
        "(`dict`, `list`, `tuple`, `collections.namedtuple`, etc.) as concrete\n",
        "representations of abstract TFF tuples. Also, although as noted above, TFF\n",
        "computations formally only accept a single parameter, you can use the familiar\n",
        "Python call syntax with positional and/or keyword arguments in case where the\n",
        "type of the parameter is a tuple - it works as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eB510nILYbId"
      },
      "source": [
        "### Gradient descent on a single batch\n",
        "\n",
        "Now, let's define a computation that uses this loss function to perform a single\n",
        "step of gradient descent. Note how in defining this function, we use\n",
        "`batch_loss` as a subcomponent. You can always invoke a computation constructed\n",
        "with `tff.tf_computation` inside the body of another computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O4uaVxw3AyYS"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  # Define a group of model variables and set them to `initial_model`.\n",
        "  model_vars = tff.utils.get_variables('v', MODEL_TYPE)\n",
        "  init_model = tff.utils.assign(model_vars, initial_model)\n",
        "\n",
        "  # Perform one step of gradient descent using loss from `batch_loss`.\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "  with tf.control_dependencies([init_model]):\n",
        "    train_model = optimizer.minimize(batch_loss(model_vars, batch))\n",
        "\n",
        "  # Return the model vars after performing this gradient descent step.\n",
        "  with tf.control_dependencies([train_model]):\n",
        "    return tff.utils.identity(model_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 103,
          "status": "ok",
          "timestamp": 1550717119139,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Y84gQsaohC38",
        "outputId": "19058e5a-d167-47c0-e409-b5e085a4b99f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,\u003cx=float32[?,784],y=int32[?]\u003e,float32\u003e -\u003e \u003cweights=float32[784,10],bias=float32[10]\u003e)'"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(batch_train.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ID8xg9FCUL2A"
      },
      "source": [
        "When you invoke a Python function decorated with `tff.tf_computation` within the\n",
        "body of another such function, the logic of the inner TFF computation that gets\n",
        "created is embedded in the logic of the outer one. You should ideally write your\n",
        "code under the assumption that the inner and outer computations are, for the\n",
        "most part, opaque to each other (thus, it's best to minimize the use of features\n",
        "such as graph introspection or the use of collections). We are actively\n",
        "experimenting with ways to support strong isolation between the inner and outer\n",
        "computations, and if you rely on graph introspection, certain patterns may\n",
        "break. That said, `batch_train` as written above does rely on the ability to\n",
        "trace through the `batch_loss`'s graph in order to compute the gradients.\n",
        "\n",
        "Now, let's apply this function a few times to the initial model to see whether\n",
        "the loss decreases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8edcJTlXUULm"
      },
      "outputs": [],
      "source": [
        "model = initial_model\n",
        "losses = []\n",
        "for _ in range(5):\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  losses.append(batch_loss(model, sample_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 109,
          "status": "ok",
          "timestamp": 1550717120940,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "3n1onojT1zHv",
        "outputId": "c2f28646-4ff4-4c6b-f53a-077a1ac000ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.19690022, 0.13176313, 0.10113225, 0.082738116, 0.070301391]"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EQk4Ha8PU-3P"
      },
      "source": [
        "### Gradient descent on a sequence of local data\n",
        "\n",
        "Now, since `batch_train` appears to work, let's write a similar training\n",
        "function `local_train` that consumes the entire sequence of all batches from one\n",
        "user instead of just a single batch. The new computation will need to now\n",
        "consume `tff.SequenceType(BATCH_TYPE)` instead of `BATCH_TYPE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EfPD5a6QVNXM"
      },
      "outputs": [],
      "source": [
        "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
        "def local_train(initial_model, learning_rate, all_batches):\n",
        "\n",
        "  # Mapping function to apply to each batch.\n",
        "  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "  def batch_fn(model, batch):\n",
        "    return batch_train(model, batch, learning_rate)\n",
        "\n",
        "  return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 108,
          "status": "ok",
          "timestamp": 1550717121387,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "sAhkS5yKUgjC",
        "outputId": "690badb5-5b0a-456e-8669-b1c4ecfc13c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,float32,\u003cx=float32[?,784],y=int32[?]\u003e*\u003e -\u003e \u003cweights=float32[784,10],bias=float32[10]\u003e)'"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(local_train.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EYT-SiopYBtH"
      },
      "source": [
        "There are quite a few details buried in this short section of code, let's go\n",
        "over them one by one.\n",
        "\n",
        "First, while we could have implemented this logic entirely in TensorFlow,\n",
        "relying on `tf.data.Dataset.reduce` to process the sequence similarly to how\n",
        "we've done it earlier, we've opted this time to express the logic in the glue\n",
        "language, as a `tff.federated_computation`. We've used the federated operator\n",
        "`tff.sequence_reduce` to perform the reduction.\n",
        "\n",
        "The operator `tff.sequence_reduce` is used similarly to\n",
        "`tf.data.Dataset.reduce`. You can think of it as essentially the same as\n",
        "`tf.data.Dataset.reduce`, but for use inside federated computations, which as\n",
        "you may remember, cannot contain TensorFlow code. It as a template operator with\n",
        "a formal parameter 3-tuple that consists of a *sequence* of `T`-typed elements,\n",
        "the initial state of the reduction (we'll refer to it abstractly as *zero*) of\n",
        "some type `U`, and the *reduction operator* of type `(U,T-\u003eU)` that alters the\n",
        "state of the reduction by processing a single element. The result is the final\n",
        "state of the reduction, after processing all elements in a sequential order. In\n",
        "our example, the state of the reduction is the model trained on a prefix of the\n",
        "data, and the elements are data batches.\n",
        "\n",
        "Second, note that we have again used one computation (`batch_train`) as a\n",
        "component within another (`local_train`), but not directly. We can't use it as a\n",
        "reduction operator because it takes an additional parameter - the learning rate.\n",
        "\n",
        "To work around the fact that `batch_train` takes an additional parameter, we\n",
        "define an embedded federated computation `batch_fn` that binds to the\n",
        "`local_train`'s parameter `learning_rate` in its body. It is allowed for a child\n",
        "computation defined this way to capture a formal parameter of its parent as long\n",
        "as the child computation is not invoked outside the body of its parent. You can\n",
        "think of this pattern as an equivalent of `functools.partial` in Python.\n",
        "\n",
        "The practical implication of capturing `learning_rate` this way is, of course,\n",
        "that the same learning rate value is used across all batches.\n",
        "\n",
        "Now, let's try the newly defined local training function on the entire sequence\n",
        "of data from the same user who contributed the sample batch (digit `5`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EnWFLoZGcSby"
      },
      "outputs": [],
      "source": [
        "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y0UXUqGk9zoF"
      },
      "source": [
        "Did it work? To answer this question, we need to implement evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a8WDKu6WYy__"
      },
      "source": [
        "### Local evaluation\n",
        "\n",
        "Here's one way to implement local evaluation by adding up the losses across all data\n",
        "batches (we could have just as well computed the average; we'll leave it as an\n",
        "exercise for the reader)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0RiODuc6z7Ln"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval(model, all_batches):\n",
        "  # TODO(b/120157713): Replace with `tff.sequence_average()` once implemented.\n",
        "  return tff.sequence_sum(\n",
        "      tff.sequence_map(\n",
        "          tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),\n",
        "          all_batches))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 110,
          "status": "ok",
          "timestamp": 1550717124039,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "pH2XPEAKa4Dg",
        "outputId": "611a59b8-fa9e-4342-9bee-deb451da2080"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,\u003cx=float32[?,784],y=int32[?]\u003e*\u003e -\u003e float32)'"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(local_eval.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "efX81HuE-BcO"
      },
      "source": [
        "Again, there are a few new elements illustrated by this code, let's go over them\n",
        "one by one.\n",
        "\n",
        "First, we have used two new federated operators for processing sequences:\n",
        "`tff.sequence_map` that takes a *mapping function* `T-\u003eU` and a *sequence* of\n",
        "`T`, and emits a sequence of `U` obtained by applying the mapping function\n",
        "pointwise, and `tff.sequence_sum` that just adds all the elements. Here, we map\n",
        "each data batch to a loss value, and then add the resulting loss values to\n",
        "compute the total loss.\n",
        "\n",
        "Note that we could have again used `tff.sequence_reduce`, but this wouldn't be\n",
        "the best choice - the reduction process is, by definition, sequential, whereas\n",
        "the mapping and sum can be computed in parallel. When given a choice, it's best\n",
        "to stick with operators that don't constrain implementation choices, so that\n",
        "when our TFF computation is compiled in the future to be deployed to a specific\n",
        "environment, one can take full advantage of all potential opportunities for a\n",
        "faster, more scalable, more resource-efficient execution.\n",
        "\n",
        "Second, note that just as in `local_train`, the component function we need\n",
        "(`batch_loss`) takes more parameters than what the federated operator\n",
        "(`tff.sequence_map`) expects - in this case, the operator wants a function that\n",
        "maps batches to losses, but `batch_loss` also takes a model. Just as we did with\n",
        "the learning rate, we use an embedded computation that captures the\n",
        "`local_eval`'s model in its body in very much the same way we previously\n",
        "captured `learning_rate` in `local_train`'s embedded computation `batch_fn`,\n",
        "thus once again effectively defining a *partial* (a computation with a subset of\n",
        "parameters bound, and the type signature modified to reflect this).\n",
        "\n",
        "The one major difference compared to the previous example is that this time,\n",
        "rather than defining a Python function with `tff.federated_computation` used as\n",
        "a decorator, we've defined the computation inline, by invoking\n",
        "`tff.federated_computation` as an ordinary function (not as a decorator), with a\n",
        "Python lambda and a type signature as arguments. This inline style of defining\n",
        "TFF computations mirrors the use of `lambda` expressions in Python, and can be a\n",
        "good choice for short sections of code like this one.\n",
        "\n",
        "Now, let's see whether our training worked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 428,
          "status": "ok",
          "timestamp": 1550717124566,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "vPw6JSVf5q_x",
        "outputId": "42f289b3-6f47-4d90-999d-906e769d92bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23.025854"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(initial_model, federated_train_data[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 475,
          "status": "ok",
          "timestamp": 1550717125131,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "se4U4lv0C3ao",
        "outputId": "356235d3-e9ec-4fac-fb10-208eec75d82a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.43484691"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(locally_trained_model, federated_train_data[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Tvu70cnBsUf"
      },
      "source": [
        "Indeed, the loss decreased. But what happens if we evaluated it on another\n",
        "user's data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 463,
          "status": "ok",
          "timestamp": 1550717125704,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "gjF0NYAj5wls",
        "outputId": "1b1ee085-cc3c-41c8-c6b8-f3e589fe19cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23.025854"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(initial_model, federated_train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 484,
          "status": "ok",
          "timestamp": 1550717126270,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Sh3POrknC_MK",
        "outputId": "d9349c21-a5c7-4017-bfaf-d4e3a53e7dc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "74.500748"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(locally_trained_model, federated_train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7WPumnRTBzUs"
      },
      "source": [
        "As expected, things got worse. The model was trained to recognize `5`, and has\n",
        "never seen a `0`. This brings the question - how did the local training impact\n",
        "the quality of the model from the global perspective?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJnL2mQRZKTO"
      },
      "source": [
        "### Federated evaluation\n",
        "\n",
        "This is the point in our journey where we finally circle back to federated types\n",
        "and federated computations - the topic that we started with. Here's a pair of\n",
        "TFF types definitions for the model that originates at the server, and the data\n",
        "that remains on the clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LjGGhpoEBh_6"
      },
      "outputs": [],
      "source": [
        "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)\n",
        "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4gTXV2-jZtE3"
      },
      "source": [
        "With all the definitions introduced so far, expressing federated evaluation in\n",
        "TFF is a one-liner - we distribute the model to clients, let each client invoke\n",
        "local evaluation on its local portion of data, and then average out the loss.\n",
        "Here's one way to write this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2zChEPzEBx4T"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval(model, data):\n",
        "  return tff.federated_average(\n",
        "      tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IWcNONNWaE0N"
      },
      "source": [
        "We've already seen examples of `tff.federated_average` and `tff.federated_map`\n",
        "in simpler scenarios, and at the intuitive level, they work as expected, but\n",
        "there's more in this section of code than meets the eye, so let's go over it\n",
        "carefully.\n",
        "\n",
        "First, let's break down the *let each client invoke local evaluation on its\n",
        "local portion of data* part. As you may recall from the preceding sections,\n",
        "`local_eval` has a type signature of the form `(\u003cMODEL_TYPE, LOCAL_DATA_TYPE\u003e -\u003e\n",
        "float32)`.\n",
        "\n",
        "The federated operator `tff.federated_map` is a template that accepts as a\n",
        "parameter a 2-tuple that consists of the *mapping function* of some type `T-\u003eU`\n",
        "and a federated value of type `{T}@CLIENTS` (i.e., with member constituents of\n",
        "the same type as the parameter of the mapping function), and returns a result of\n",
        "type `{U}@CLIENTS`.\n",
        "\n",
        "Since we're feeding `local_eval` as a mapping function to apply on a per-client\n",
        "basis, the second argument should be a federated of type `\u003cMODEL_TYPE,\n",
        "LOCAL_DATA_TYPE\u003e@CLIENTS`, i.e., in the nomenclature of the preceding sections,\n",
        "it should be a federated tuple. Each client should hold a full set of arguments\n",
        "for `local_eval` as a member consituent. Instead, we're feeding it a 2-element\n",
        "Python `list`. What's happening here?\n",
        "\n",
        "Indeed, this is an example of an *implicit type cast* in TFF, similar to\n",
        "implicit type casts you may have encountered elsewhere, e.g., when you feed an\n",
        "`int` to a function that accepts a `float`. Implicit casting is used scarcily at\n",
        "this point, but we plan to make it more pervasive in TFF as a way to minimize\n",
        "boilerplate.\n",
        "\n",
        "The implicit cast that's applied in this case is the equivalence between\n",
        "federated tuples of the form `\u003cX,Y\u003e@Z`, and tuples of federated values\n",
        "`\u003cX@Z,Y@Z\u003e`. While formally, these two are different type signatures, looking at\n",
        "it from the programmers's perspective, each device in `Z` holds two units of\n",
        "data `X` and `Y`. What happens here is not unlike `zip` in Python, and indeed,\n",
        "we offer an operator `tff.federated_zip` that allows you to perform such\n",
        "conversions explicity. When the `tff.federated_map` encounters a tuple as a\n",
        "second argument, it simply invokes `tff.federated_zip` for you.\n",
        "\n",
        "Given the above, you should now be able to recognize the expression\n",
        "`tff.federated_broadcast(model)` as representing a value of TFF type\n",
        "`{MODEL_TYPE}@CLIENTS`, and `data` as a value of TFF type\n",
        "`{LOCAL_DATA_TYPE}@CLIENTS` (or simply `CLIENT_DATA_TYPE`), the two getting\n",
        "filtered together through an implicit `tff.federated_zip` to form the second\n",
        "argument to `tff.federated_map`.\n",
        "\n",
        "The operator `tff.federated_broadcast`, as you'd expect, simply transfers data\n",
        "from the server to the clients.\n",
        "\n",
        "Now, let's see how our local training affected the average loss in the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3764,
          "status": "ok",
          "timestamp": 1550717130461,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "TXgnzTDvCGQ4",
        "outputId": "eeaa9cbe-9fcd-4167-cc59-7f732cc7141b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23.025852"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(initial_model, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3442,
          "status": "ok",
          "timestamp": 1550717134003,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "sR2b0la_CWQr",
        "outputId": "d1a5c8e3-199c-41b1-cfa7-83bfb6d6df89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "54.432625"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(locally_trained_model, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LQi2rGX_fK7i"
      },
      "source": [
        "Indeed, as expected, the loss has increased. In order to improve the model for\n",
        "all users, we'll need to train in on everyone's data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vkw9f59qfS7o"
      },
      "source": [
        "### Federated training\n",
        "\n",
        "The simplest way to implement federated training is to locally train, and then\n",
        "average the models. This uses the same building blocks and patters we've already\n",
        "discussed, as you can see below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mBOC4uoG6dd-"
      },
      "outputs": [],
      "source": [
        "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)\n",
        "\n",
        "@tff.federated_computation(\n",
        "    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_train(model, learning_rate, data):\n",
        "  return tff.federated_average(\n",
        "      tff.federated_map(\n",
        "          local_train,\n",
        "          [tff.federated_broadcast(model),\n",
        "           tff.federated_broadcast(learning_rate),\n",
        "           data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z2vACMsQjzO1"
      },
      "source": [
        "In reality, rather than averaging the models, we prefer to average model deltas,\n",
        "for a number of reasons, e.g., such as the ability to clip their norms, for\n",
        "compression, etc. This is a relatively simple change in TFF, as you'll just need\n",
        "to subtract the model from the argument to `tff.federated_average`, and then add\n",
        "it back to the result - we omit it here to keep things simple.\n",
        "\n",
        "Let's see whether the training works by running a few rounds of training and\n",
        "comparing the average loss before and after."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NLx-3rLs9jGY"
      },
      "outputs": [],
      "source": [
        "#@test {\"timeout\": 600}\n",
        "model = initial_model\n",
        "learning_rate = 0.1\n",
        "losses = []\n",
        "for _ in range(5):\n",
        "  model = federated_train(model, learning_rate, federated_train_data)\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  losses.append(federated_eval(model, federated_train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 304,
          "status": "ok",
          "timestamp": 1550717262740,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "vPLD8UHSI-eP",
        "outputId": "69da73ea-6e6c-4b20-d389-509dc6d344a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[21.605524, 20.365679, 19.274801, 18.31111, 17.457254]"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0VjSLQzlUIp"
      },
      "source": [
        "For completeness, let's now also run on the test data to confirm that our model\n",
        "generalizes well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3441,
          "status": "ok",
          "timestamp": 1550717266253,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ZaZT45yFMOaM",
        "outputId": "c5c120de-dc2c-450e-fa51-9b9c01bc765e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.795593"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(initial_model, federated_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3333,
          "status": "ok",
          "timestamp": 1550717269647,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "A9Uk7NpFM1Ho",
        "outputId": "80cc0e74-56c7-4ada-928c-e797b00ff7d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17.278767"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(model, federated_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pxlHHwLGlgFB"
      },
      "source": [
        "This concludes our tutorial.\n",
        "\n",
        "Of course, our simplified example doesn't reflect a number of things you'd need\n",
        "to do in a more realistic scenario - for example, we haven't computed metrics\n",
        "other than loss. We encourage you to study\n",
        "[the implementation](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/learning/federated_averaging.py)\n",
        "of federated averaging in `tff.learning` as a more complete example, and as a\n",
        "way to demonstrate some of the coding practices we'd like to encourage."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Custom Federated Algorithms, Part 2: Implementing Federated Averaging",
      "provenance": [
        {
          "file_id": "1FuV5nQFsa54XJSahUG0RwZpPGQzdTz_D",
          "timestamp": 1547078723514
        }
      ],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
